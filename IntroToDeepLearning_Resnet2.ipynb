{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNnTrJkqIeM2pWMz44zciyT"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["# ResNet101\n","upload transposed2.Rds"],"metadata":{"id":"Nsis3K6MKQFN"}},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-lWKHPsbqycJ","executionInfo":{"status":"ok","timestamp":1699575751701,"user_tz":600,"elapsed":47064,"user":{"displayName":"Joshua Burkhart","userId":"09471866206613143181"}},"outputId":"68d9df94-995f-4948-ab96-06da34a8028e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch: 0, Train Acc: 0.06944444444444445\n","Epoch: 1, Train Acc: 0.1597222222222222\n","Epoch: 2, Train Acc: 0.3159722222222222\n","Epoch: 3, Train Acc: 0.4513888888888889\n","Epoch: 4, Train Acc: 0.3958333333333333\n","Epoch: 5, Train Acc: 0.5381944444444444\n","Epoch: 6, Train Acc: 0.5659722222222222\n","Epoch: 7, Train Acc: 0.65625\n","Epoch: 8, Train Acc: 0.6979166666666666\n","Epoch: 9, Train Acc: 0.6909722222222222\n","Epoch: 10, Train Acc: 0.8576388888888888\n","Epoch: 11, Train Acc: 0.9305555555555556\n","Epoch: 12, Train Acc: 0.8576388888888888\n","Epoch: 13, Train Acc: 0.6805555555555556\n","Epoch: 14, Train Acc: 0.2743055555555556\n","Epoch: 15, Train Acc: 0.7430555555555556\n","Epoch: 16, Train Acc: 0.9340277777777778\n","Epoch: 17, Train Acc: 0.9027777777777778\n","Epoch: 18, Train Acc: 0.8993055555555556\n","Epoch: 19, Train Acc: 0.8784722222222222\n","Epoch: 20, Train Acc: 0.9097222222222222\n","Epoch: 21, Train Acc: 0.8993055555555556\n","Epoch: 22, Train Acc: 0.9270833333333334\n","Epoch: 23, Train Acc: 0.9548611111111112\n","Epoch: 24, Train Acc: 0.9201388888888888\n","Epoch: 25, Train Acc: 0.7673611111111112\n","Epoch: 26, Train Acc: 0.7222222222222222\n","Epoch: 27, Train Acc: 0.2847222222222222\n","Epoch: 28, Train Acc: 0.4861111111111111\n","Epoch: 29, Train Acc: 0.8263888888888888\n","Epoch: 30, Train Acc: 0.9548611111111112\n","Epoch: 31, Train Acc: 0.9826388888888888\n","Epoch: 32, Train Acc: 0.9895833333333334\n","Epoch: 33, Train Acc: 0.96875\n","Epoch: 34, Train Acc: 0.9652777777777778\n","Epoch: 35, Train Acc: 0.9166666666666666\n","Epoch: 36, Train Acc: 0.96875\n","Epoch: 37, Train Acc: 0.9895833333333334\n","Epoch: 38, Train Acc: 0.9895833333333334\n","Epoch: 39, Train Acc: 0.9930555555555556\n","Epoch: 40, Train Acc: 0.9965277777777778\n","Epoch: 41, Train Acc: 1.0\n"]}],"source":["import rpy2.robjects as ro\n","from rpy2.robjects import r\n","import torch\n","from rpy2.robjects import pandas2ri\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import models\n","from torch import nn\n","from rpy2.robjects.conversion import localconverter\n","\n","torch.manual_seed(88888888)\n","\n","DATA_PATH = 'transposed2.Rds' #'/home/jgburk/PycharmProjects/IntroductionToDeepLearning/transposed.Rds'\n","NUM_FEATURES = 1000\n","NUM_CLASSES = 7\n","NUM_TRAIN_IT = 1000\n","\n","BATCH_SIZE = 32\n","\n","\n","class PandasDataset(Dataset):\n","\n","    def __init__(self, rds_fn):\n","      with localconverter(ro.default_converter + pandas2ri.converter):\n","        df = ro.conversion.rpy2py(r.readRDS(rds_fn))\n","\n","        features = df.iloc[:, 0:NUM_FEATURES].values\n","        targets = df['sample_type'].values\n","\n","        self.x = torch.tensor(features)\n","        self.y = torch.tensor(targets - 1)\n","\n","    def __len__(self):\n","        return len(self.y)\n","\n","    def __getitem__(self, i):\n","        return self.x[i], self.y[i]\n","\n","\n","def train(loader, dv):\n","    model.train()\n","\n","    correct = 0\n","    for batch in loader:  # Iterate in batches over the training dataset.\n","        x = batch[0].reshape(BATCH_SIZE, 10, 10, 10).to(dv)\n","        y = batch[1].to(dv)\n","        out = model(x.float())  # Perform a single forward pass.\n","        y = torch.squeeze(y)\n","        loss = criterion(out, y.long())  # Compute the loss.\n","        loss.backward()  # Derive gradients.\n","        optimizer.step()  # Update parameters based on gradients.\n","        optimizer.zero_grad()  # Clear gradients.\n","        pred = out.argmax(dim=1)  # Use the class with highest probability.\n","        correct += int((pred == y).sum())  # Check against ground-truth labels.\n","    return correct / len(loader.dataset)  # Derive ratio of correct predictions.\n","\n","\n","rds_dataset = PandasDataset(DATA_PATH)\n","training_loader = DataLoader(rds_dataset, batch_size=BATCH_SIZE, shuffle=False)\n","\n","model = models.resnet101(num_classes=NUM_CLASSES) # resnet with 101 layers\n","conv1 = model.conv1\n","model.conv1 = nn.Conv2d(10,\n","                        conv1.out_channels,\n","                        conv1.kernel_size,\n","                        conv1.stride,\n","                        conv1.padding,\n","                        conv1.dilation,\n","                        conv1.groups,\n","                        conv1.bias)\n","device = torch.device('cuda')\n","model.to(device)\n","optimizer = torch.optim.AdamW(model.parameters())\n","criterion = torch.nn.CrossEntropyLoss()\n","\n","for epoch in range(NUM_TRAIN_IT):\n","    train(training_loader, device)\n","    train_acc = train(training_loader, device)\n","    print(f'Epoch: {epoch}, Train Acc: {train_acc}')\n","    if train_acc == 1.0:\n","        break"]}]}