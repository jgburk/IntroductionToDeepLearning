{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNQDlDSJEDUz1rIIKWABoz+"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["# ConvNeXt\n","upload transposed2.Rds"],"metadata":{"id":"oyd8nWCSKDHM"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"89ksIIKSwClK","outputId":"ea5e63f8-2384-4aa7-abf6-8405c8b8bc29","executionInfo":{"status":"ok","timestamp":1699576514209,"user_tz":600,"elapsed":53078,"user":{"displayName":"Joshua Burkhart","userId":"09471866206613143181"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch: 0, Train Acc: 0.034722222222222224\n","Epoch: 1, Train Acc: 0.013888888888888888\n","Epoch: 2, Train Acc: 0.14583333333333334\n","Epoch: 3, Train Acc: 0.04861111111111111\n","Epoch: 4, Train Acc: 0.13194444444444445\n","Epoch: 5, Train Acc: 0.2847222222222222\n","Epoch: 6, Train Acc: 0.3402777777777778\n","Epoch: 7, Train Acc: 0.28125\n","Epoch: 8, Train Acc: 0.2916666666666667\n","Epoch: 9, Train Acc: 0.3263888888888889\n","Epoch: 10, Train Acc: 0.3645833333333333\n","Epoch: 11, Train Acc: 0.1423611111111111\n","Epoch: 12, Train Acc: 0.3819444444444444\n","Epoch: 13, Train Acc: 0.3402777777777778\n","Epoch: 14, Train Acc: 0.4270833333333333\n","Epoch: 15, Train Acc: 0.5347222222222222\n","Epoch: 16, Train Acc: 0.4722222222222222\n","Epoch: 17, Train Acc: 0.5555555555555556\n","Epoch: 18, Train Acc: 0.5034722222222222\n","Epoch: 19, Train Acc: 0.6284722222222222\n","Epoch: 20, Train Acc: 0.5277777777777778\n","Epoch: 21, Train Acc: 0.5902777777777778\n","Epoch: 22, Train Acc: 0.4930555555555556\n","Epoch: 23, Train Acc: 0.3784722222222222\n","Epoch: 24, Train Acc: 0.4965277777777778\n","Epoch: 25, Train Acc: 0.6597222222222222\n","Epoch: 26, Train Acc: 0.6875\n","Epoch: 27, Train Acc: 0.6354166666666666\n","Epoch: 28, Train Acc: 0.6631944444444444\n","Epoch: 29, Train Acc: 0.7430555555555556\n","Epoch: 30, Train Acc: 0.6319444444444444\n","Epoch: 31, Train Acc: 0.7083333333333334\n","Epoch: 32, Train Acc: 0.7569444444444444\n","Epoch: 33, Train Acc: 0.5868055555555556\n","Epoch: 34, Train Acc: 0.5798611111111112\n","Epoch: 35, Train Acc: 0.7395833333333334\n","Epoch: 36, Train Acc: 0.7777777777777778\n","Epoch: 37, Train Acc: 0.8576388888888888\n","Epoch: 38, Train Acc: 0.8090277777777778\n","Epoch: 39, Train Acc: 0.7222222222222222\n","Epoch: 40, Train Acc: 0.8159722222222222\n","Epoch: 41, Train Acc: 0.8888888888888888\n","Epoch: 42, Train Acc: 0.875\n","Epoch: 43, Train Acc: 0.78125\n","Epoch: 44, Train Acc: 0.9097222222222222\n","Epoch: 45, Train Acc: 0.9618055555555556\n","Epoch: 46, Train Acc: 0.9479166666666666\n","Epoch: 47, Train Acc: 0.8923611111111112\n","Epoch: 48, Train Acc: 0.9027777777777778\n","Epoch: 49, Train Acc: 0.78125\n","Epoch: 50, Train Acc: 0.6493055555555556\n","Epoch: 51, Train Acc: 0.8958333333333334\n","Epoch: 52, Train Acc: 0.9791666666666666\n","Epoch: 53, Train Acc: 0.9548611111111112\n","Epoch: 54, Train Acc: 0.8888888888888888\n","Epoch: 55, Train Acc: 0.75\n","Epoch: 56, Train Acc: 0.8715277777777778\n","Epoch: 57, Train Acc: 0.9895833333333334\n","Epoch: 58, Train Acc: 1.0\n"]}],"source":["import rpy2.robjects as ro\n","from rpy2.robjects import r\n","import torch\n","from rpy2.robjects import pandas2ri\n","from torch.nn import Conv2d\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import models\n","from torch import nn\n","from rpy2.robjects.conversion import localconverter\n","\n","torch.manual_seed(88888888)\n","\n","DATA_PATH = 'transposed2.Rds' #'/home/jgburk/PycharmProjects/IntroductionToDeepLearning/transposed.Rds'\n","NUM_FEATURES = 1000\n","NUM_CLASSES = 7\n","NUM_TRAIN_IT = 1000\n","\n","CNVNXT_CHNLS = 3\n","CNVNXT_CST_D1 = 18\n","CNVNXT_CST_D2 = 19\n","\n","assert (CNVNXT_CHNLS * CNVNXT_CST_D1 * CNVNXT_CST_D2) > NUM_FEATURES\n","\n","BATCH_SIZE = 32\n","\n","\n","class PandasDataset(Dataset):\n","\n","    def __init__(self, rds_fn):\n","      with localconverter(ro.default_converter + pandas2ri.converter):\n","        df = ro.conversion.rpy2py(r.readRDS(rds_fn))\n","\n","        features = df.iloc[:, 0:NUM_FEATURES].values\n","        targets = df['sample_type'].values\n","\n","        unpadded = torch.tensor(features)\n","        padded = torch.nn.ConstantPad1d((0, (CNVNXT_CHNLS * CNVNXT_CST_D1 * CNVNXT_CST_D2) - NUM_FEATURES), 0)(unpadded)\n","        self.x = padded\n","        self.y = torch.tensor(targets - 1)\n","\n","    def __len__(self):\n","        return len(self.y)\n","\n","    def __getitem__(self, i):\n","        return self.x[i], self.y[i]\n","\n","\n","def train(loader, dv):\n","    model.train()\n","\n","    correct = 0\n","    for batch in loader:  # Iterate in batches over the training dataset.\n","        x = batch[0].reshape(BATCH_SIZE, CNVNXT_CHNLS, CNVNXT_CST_D1, CNVNXT_CST_D2).to(dv)\n","        y = batch[1].to(dv)\n","        out = model(x.float())  # Perform a single forward pass.\n","        y = torch.squeeze(y)\n","        loss = criterion(out, y.long())  # Compute the loss.\n","        loss.backward()  # Derive gradients.\n","        optimizer.step()  # Update parameters based on gradients.\n","        optimizer.zero_grad()  # Clear gradients.\n","        pred = out.argmax(dim=1)  # Use the class with highest probability.\n","        correct += int((pred == y).sum())  # Check against ground-truth labels.\n","    return correct / len(loader.dataset)  # Derive ratio of correct predictions.\n","\n","\n","rds_dataset = PandasDataset(DATA_PATH)\n","training_loader = DataLoader(rds_dataset, batch_size=BATCH_SIZE, shuffle=False)\n","\n","model = models.convnext_tiny()\n","conv2d = model._modules['features'][6][1]\n","model._modules['features'][6][1] = Conv2d(in_channels=conv2d.in_channels,\n","                                          out_channels=conv2d.out_channels,\n","                                          kernel_size=conv2d.kernel_size,\n","                                          stride=conv2d.stride,\n","                                          padding=1)\n","device = torch.device('cuda')\n","model.to(device)\n","\n","optimizer = torch.optim.AdamW(model.parameters())\n","criterion = torch.nn.CrossEntropyLoss()\n","\n","for epoch in range(NUM_TRAIN_IT):\n","    train(training_loader, device)\n","    train_acc = train(training_loader, device)\n","    print(f'Epoch: {epoch}, Train Acc: {train_acc}')\n","    if train_acc == 1.0:\n","        break"]}]}