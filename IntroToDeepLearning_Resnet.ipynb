{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyN9g24clruyO4q2lMCEGpZ6"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# ResNet18\n","upload transposed2.Rds"],"metadata":{"id":"6QZsyY1rX2Oy"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iZm9UISiXkfg","executionInfo":{"status":"ok","timestamp":1699576020953,"user_tz":600,"elapsed":167025,"user":{"displayName":"Joshua Burkhart","userId":"09471866206613143181"}},"outputId":"8a2ca8dc-fb13-438c-afed-e00b0290f0d8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch: 0, Train Acc: 0.14930555555555555\n","Epoch: 1, Train Acc: 0.1840277777777778\n","Epoch: 2, Train Acc: 0.3472222222222222\n","Epoch: 3, Train Acc: 0.3993055555555556\n","Epoch: 4, Train Acc: 0.3715277777777778\n","Epoch: 5, Train Acc: 0.3368055555555556\n","Epoch: 6, Train Acc: 0.4965277777777778\n","Epoch: 7, Train Acc: 0.6284722222222222\n","Epoch: 8, Train Acc: 0.4201388888888889\n","Epoch: 9, Train Acc: 0.5520833333333334\n","Epoch: 10, Train Acc: 0.6909722222222222\n","Epoch: 11, Train Acc: 0.6909722222222222\n","Epoch: 12, Train Acc: 0.7604166666666666\n","Epoch: 13, Train Acc: 0.6701388888888888\n","Epoch: 14, Train Acc: 0.5486111111111112\n","Epoch: 15, Train Acc: 0.7673611111111112\n","Epoch: 16, Train Acc: 0.8576388888888888\n","Epoch: 17, Train Acc: 0.8194444444444444\n","Epoch: 18, Train Acc: 0.8715277777777778\n","Epoch: 19, Train Acc: 0.96875\n","Epoch: 20, Train Acc: 0.96875\n","Epoch: 21, Train Acc: 0.9618055555555556\n","Epoch: 22, Train Acc: 0.9583333333333334\n","Epoch: 23, Train Acc: 0.9305555555555556\n","Epoch: 24, Train Acc: 0.9270833333333334\n","Epoch: 25, Train Acc: 0.9895833333333334\n","Epoch: 26, Train Acc: 1.0\n"]}],"source":["import rpy2.robjects as ro\n","from rpy2.robjects import r\n","import torch\n","from rpy2.robjects import pandas2ri\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import models\n","from torch import nn\n","from rpy2.robjects.conversion import localconverter\n","\n","\n","torch.manual_seed(88888888)\n","\n","DATA_PATH = 'transposed2.Rds' #/home/jgburk/PycharmProjects/IntroductionToDeepLearning/transposed.Rds'\n","NUM_FEATURES = 1000\n","NUM_CLASSES = 7\n","NUM_TRAIN_IT = 1000\n","\n","BATCH_SIZE = 32\n","\n","class PandasDataset(Dataset):\n","\n","    def __init__(self, rds_fn):\n","      with localconverter(ro.default_converter + pandas2ri.converter):\n","        df = ro.conversion.rpy2py(r.readRDS(rds_fn))\n","\n","        features = df.iloc[:, 0:NUM_FEATURES].values\n","        targets = df['sample_type'].values\n","\n","        self.x = torch.tensor(features)\n","        self.y = torch.tensor(targets - 1)\n","\n","    def __len__(self):\n","        return len(self.y)\n","\n","    def __getitem__(self, i):\n","        return self.x[i], self.y[i]\n","\n","\n","def train(loader, dv):\n","    model.train()\n","\n","    correct = 0\n","    for batch in loader:  # Iterate in batches over the training dataset.\n","        x = batch[0].reshape(BATCH_SIZE, 10, 10, 10).to(dv)\n","        y = batch[1].to(dv)\n","        out = model(x.float())  # Perform a single forward pass.\n","        y = torch.squeeze(y)\n","        loss = criterion(out, y.long())  # Compute the loss.\n","        loss.backward()  # Derive gradients.\n","        optimizer.step()  # Update parameters based on gradients.\n","        optimizer.zero_grad()  # Clear gradients.\n","        pred = out.argmax(dim=1)  # Use the class with highest probability.\n","        correct += int((pred == y).sum())  # Check against ground-truth labels.\n","    return correct / len(loader.dataset)  # Derive ratio of correct predictions.\n","\n","\n","rds_dataset = PandasDataset(DATA_PATH)\n","training_loader = DataLoader(rds_dataset, batch_size=BATCH_SIZE, shuffle=False)\n","\n","model = models.resnet18(num_classes=NUM_CLASSES) # resnet with 18 layers\n","conv1 = model.conv1\n","model.conv1 = nn.Conv2d(10,\n","                        conv1.out_channels,\n","                        conv1.kernel_size,\n","                        conv1.stride,\n","                        conv1.padding,\n","                        conv1.dilation,\n","                        conv1.groups,\n","                        conv1.bias)\n","device = cpu = torch.device('cpu')\n","\n","optimizer = torch.optim.AdamW(model.parameters())\n","criterion = torch.nn.CrossEntropyLoss()\n","\n","for epoch in range(NUM_TRAIN_IT):\n","    train(training_loader, device)\n","    train_acc = train(training_loader, device)\n","    print(f'Epoch: {epoch}, Train Acc: {train_acc}')\n","    if train_acc == 1.0:\n","        break"]}]}